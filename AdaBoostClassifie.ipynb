{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13faf9a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-02T02:27:09.265003Z",
     "start_time": "2023-02-02T02:27:09.251759Z"
    }
   },
   "source": [
    "### sklearn.ensemble.AdaBoostClassifie\n",
    "\n",
    "* _class_ sklearn.ensemble.AdaBoostClassifier(_base_estimator=None_, _*_, _n_estimators=50_, _learning_rate=1.0_, _algorithm='SAMME.R'_, _random_state=None_)[[source]](https://github.com/scikit-learn/scikit-learn/blob/f3f51f9b6/sklearn/ensemble/_weight_boosting.py#L328)[¶](https://scikit-learn.org/1.1/modules/generated/sklearn.ensemble.AdaBoostClassifier.html?highlight=ada+boost#sklearn.ensemble.AdaBoostClassifier \"Permalink to this definition\")\n",
    "\n",
    "Parameters:\n",
    "\n",
    "**base_estimator**object, default=None\n",
    "\n",
    "The base estimator from which the boosted ensemble is built. Support for sample weighting is required, as well as proper  `classes_`  and  `n_classes_`  attributes. If  `None`, then the base estimator is  [`DecisionTreeClassifier`](https://scikit-learn.org/1.1/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier \"sklearn.tree.DecisionTreeClassifier\")  initialized with  `max_depth=1`.\n",
    "\n",
    "**n_estimators**int, default=50\n",
    "\n",
    "The maximum number of estimators at which boosting is terminated. In case of perfect fit, the learning procedure is stopped early. Values must be in the range  `[1,  inf)`.\n",
    "\n",
    "**learning_rate**float, default=1.0\n",
    "\n",
    "Weight applied to each classifier at each boosting iteration. A higher learning rate increases the contribution of each classifier. There is a trade-off between the  `learning_rate`  and  `n_estimators`  parameters. Values must be in the range  `(0.0,  inf)`.\n",
    "\n",
    "**algorithm**{‘SAMME’, ‘SAMME.R’}, default=’SAMME.R’\n",
    "\n",
    "If ‘SAMME.R’ then use the SAMME.R real boosting algorithm.  `base_estimator`  must support calculation of class probabilities. If ‘SAMME’ then use the SAMME discrete boosting algorithm. The SAMME.R algorithm typically converges faster than SAMME, achieving a lower test error with fewer boosting iterations.\n",
    "\n",
    "**random_state**int, RandomState instance or None, default=None\n",
    "\n",
    "Controls the random seed given at each  `base_estimator`  at each boosting iteration. Thus, it is only used when  `base_estimator`  exposes a  `random_state`. Pass an int for reproducible output across multiple function calls. See  [Glossary](https://scikit-learn.org/1.1/glossary.html#term-random_state).\n",
    "\n",
    "Attributes:\n",
    "\n",
    "**base_estimator_**estimator\n",
    "\n",
    "The base estimator from which the ensemble is grown.\n",
    "\n",
    "**estimators_**list of classifiers\n",
    "\n",
    "The collection of fitted sub-estimators.\n",
    "\n",
    "**classes_**ndarray of shape (n_classes,)\n",
    "\n",
    "The classes labels.\n",
    "\n",
    "**n_classes_**int\n",
    "\n",
    "The number of classes.\n",
    "\n",
    "**estimator_weights_**ndarray of floats\n",
    "\n",
    "Weights for each estimator in the boosted ensemble.\n",
    "\n",
    "**estimator_errors_**ndarray of floats\n",
    "\n",
    "Classification error for each estimator in the boosted ensemble.\n",
    "\n",
    "[`feature_importances_`](https://scikit-learn.org/1.1/modules/generated/sklearn.ensemble.AdaBoostClassifier.html?highlight=ada+boost#sklearn.ensemble.AdaBoostClassifier.feature_importances_ \"sklearn.ensemble.AdaBoostClassifier.feature_importances_\")ndarray of shape (n_features,)\n",
    "\n",
    "The impurity-based feature importances.\n",
    "\n",
    "**n_features_in_**int\n",
    "\n",
    "Number of features seen during  [fit](https://scikit-learn.org/1.1/glossary.html#term-fit).\n",
    "\n",
    "New in version 0.24.\n",
    "\n",
    "**feature_names_in_**ndarray of shape (`n_features_in_`,)\n",
    "\n",
    "Names of features seen during  [fit](https://scikit-learn.org/1.1/glossary.html#term-fit). Defined only when  `X`  has feature names that are all strings.\n",
    "\n",
    "New in version 1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bf136c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-02T02:27:18.768755Z",
     "start_time": "2023-02-02T02:27:18.365176Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "feature_name_df = pd.read_csv(\"./datasets/human_activity/features.txt\", sep=\"\\s+\",header=None,\n",
    "           names=[\"column_index\", 'column_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d159135",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-02T02:27:22.858947Z",
     "start_time": "2023-02-02T02:27:19.048072Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column_index    42\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "feature_dup_df = feature_name_df.groupby(\"column_name\").count()\n",
    "print(feature_dup_df[feature_dup_df[\"column_index\"]>1].count())\n",
    "feature_dup_df[feature_dup_df[\"column_index\"]>1].head()\n",
    "\n",
    "\n",
    "def get_new_feature_name_df(old_feature_name_df):\n",
    "    #column_name으로 중복된 컬럼명에 대해서는 중복 차수 부여, col1, col1과 같이 2개의 중복 컬럼이 있을 경우 1, 2 \n",
    "    feature_dup_df = pd.DataFrame(data=old_feature_name_df.groupby('column_name').cumcount(), columns=['dup_cnt'])\n",
    "    # feature_dup_df의 index인 column_name을 reset_index()를 이용하여 컬럼으로 변환. \n",
    "    feature_dup_df = feature_dup_df.reset_index()\n",
    "    # 인자로 받은 features_txt의 컬럼명 DataFrame과 feature_dup_df를 조인. \n",
    "    new_feature_name_df = pd.merge(old_feature_name_df.reset_index(), feature_dup_df, how='outer')\n",
    "    # 새로운 컬럼명은 앞에 중복 차수를 접미어로 결합. \n",
    "    new_feature_name_df['column_name'] = new_feature_name_df[['column_name', 'dup_cnt']].apply(lambda x : x[0]+'_'+str(x[1]) \n",
    "                                                                                           if x[1] >0 else x[0] ,  axis=1)\n",
    "    new_feature_name_df = new_feature_name_df.drop(['index'], axis=1)\n",
    "    return new_feature_name_df\n",
    "\n",
    "def get_human_dataset( ):\n",
    "    \n",
    "    # 각 데이터 파일들은 공백으로 분리되어 있으므로 read_csv에서 공백 문자를 sep으로 할당.\n",
    "    feature_name_df = pd.read_csv('./datasets/human_activity/features.txt',sep='\\s+',\n",
    "                        header=None,names=['column_index','column_name'])\n",
    "    \n",
    "    # 중복된 feature명을 새롭게 수정하는 get_new_feature_name_df()를 이용하여 새로운 feature명 DataFrame생성. \n",
    "    new_feature_name_df = get_new_feature_name_df(feature_name_df)\n",
    "    \n",
    "    # DataFrame에 피처명을 컬럼으로 부여하기 위해 리스트 객체로 다시 변환\n",
    "    feature_name = new_feature_name_df.iloc[:, 1].values.tolist()\n",
    "    \n",
    "    # 학습 피처 데이터 셋과 테스트 피처 데이터을 DataFrame으로 로딩. 컬럼명은 feature_name 적용\n",
    "    X_train = pd.read_csv('./datasets/human_activity/train/X_train.txt',sep='\\s+', names=feature_name )\n",
    "    X_test = pd.read_csv('./datasets/human_activity/test/X_test.txt',sep='\\s+', names=feature_name)\n",
    "    \n",
    "    # 학습 레이블과 테스트 레이블 데이터을 DataFrame으로 로딩하고 컬럼명은 action으로 부여\n",
    "    y_train = pd.read_csv('./datasets/human_activity/train/y_train.txt',sep='\\s+',header=None,names=['action'])\n",
    "    y_test = pd.read_csv('./datasets/human_activity/test/y_test.txt',sep='\\s+',header=None,names=['action'])\n",
    "    \n",
    "    # 로드된 학습/테스트용 DataFrame을 모두 반환 \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_human_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df83c07c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-02T02:49:33.143524Z",
     "start_time": "2023-02-02T02:48:26.736798Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juno\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5310485239226331"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "ada_clf = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
    "ada_clf.fit(X_train,y_train)\n",
    "ada_pred = ada_clf.predict(X_test)\n",
    "ada_accuracy = accuracy_score(y_test,ada_pred)\n",
    "ada_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdec6ebf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
