{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "186c7411",
   "metadata": {},
   "source": [
    "### XGBoost\n",
    "\n",
    "* XGBoost 란?\n",
    "\n",
    "-   XGBoost는 Extreme Gradient Boosting의 약자이다.\n",
    "-   Boosting 기법을 이용하여 구현한 알고리즘은 Gradient Boost 가 대표적인데\n",
    "-   이 알고리즘을 병렬 학습이 지원되도록 구현한 라이브러리가 XGBoost 이다.\n",
    "-   Regression, Classification 문제를 모두 지원하며, 성능과 자원 효율이 좋아서, 인기 있게 사용되는 알고리즘이다.\n",
    "\n",
    "* XGBoost의 장점\n",
    "\n",
    "-   GBM 대비 빠른 수행시간\n",
    "    -   병렬 처리로 학습, 분류 속도가 빠르다.\n",
    "-   과적합 규제(Regularization)\n",
    "    -   표준 GBM 경우 과적합 규제기능이 없으나, XGBoost는 자체에 과적합 규제 기능으로 강한 내구성 지닌다.\n",
    "-   분류와 회귀영역에서 뛰어난 예측 성능 발휘\n",
    "    -   즉, CART(Classification and regression tree) 앙상블 모델을 사용\n",
    "-   Early Stopping(조기 종료) 기능이 있음\n",
    "-   다양한 옵션을 제공하며 Customizing이 용이하다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d8ca6b",
   "metadata": {},
   "source": [
    "-   XGBoost는 다수의 하이퍼파라미터가 존재하며,  **다음 세가지 범주로 나뉜다.**\n",
    "    \n",
    "    -   **일반 파라미터**\n",
    "        -   부스팅을 수행할 때 트리를 사용할지, 선형 모델을 사용할지 등을 고른다.\n",
    "    -   **부스터 파라미터**\n",
    "        -   선택한 부스터에 따라서 적용할 수 있는 파라미터 종류가 다르다.\n",
    "    -   **학습 과정 파라미터**\n",
    "        -   학습 시나리오를 결정한다.\n",
    "-   **일반 파라미터**\n",
    "    \n",
    "    -   booster [기본값 = gbtree]\n",
    "        -   어떤 부스터 구조를 쓸지 결정한다.\n",
    "        -   의사결정기반모형(gbtree), 선형모형(gblinear), dart가 있다.\n",
    "    -   n_jobs\n",
    "        -   XGBoost를 실행하는 데 사용되는 병렬 스레드 수\n",
    "    -   verbosity [기본값 = 1]\n",
    "        -   유효한 값은 0 (무음), 1 (경고), 2 (정보), 3 (디버그)\n",
    "-   **부스터 파라미터**\n",
    "    \n",
    "    -   **gbtree Booster의 파라미터**\n",
    "        -   learning_rate [ 기본값 : 0.3 ]\n",
    "            -   learning rate이다.\n",
    "            -   learning rate가 높을수록 과적합 하기 쉽다.\n",
    "        -   n_estimators [ 기본값 : 100 ]\n",
    "            -   생성할 weak learner의 수\n",
    "            -   learning_rate가 낮을 땐, n_estimators를 높여야 과적합이 방지된다.\n",
    "        -   max_depth [ 기본값 : 6 ]\n",
    "            -   트리의 maximum depth이다.\n",
    "            -   적절한 값이 제시되어야 하고 보통 3-10 사이 값이 적용된다.\n",
    "            -   max_depth가 높을수록 모델의 복잡도가 커져 과적합 하기 쉽다.\n",
    "        -   min_child_weight [ 기본값 : 1 ]\n",
    "            -   관측치에 대한 가중치 합의 최소를 말한다.\n",
    "            -   값이 높을수록 과적합이 방지된다.\n",
    "        -   gamma [ 기본값 : 0 ]\n",
    "            -   리프노드의 추가분할을 결정할 최소손실 감소값이다.\n",
    "            -   해당값보다 손실이 크게 감소할 때 분리한다.\n",
    "            -   값이 높을수록 과적합이 방지된다.\n",
    "        -   subsample [ 기본값 : 1 ]\n",
    "            -   weak learner가 학습에 사용하는 데이터 샘플링 비율이다.\n",
    "            -   보통 0.5 ~ 1 사용된다.\n",
    "            -   값이 낮을수록 과적합이 방지된다.\n",
    "        -   colsample_bytree [ 기본값 : 1 ]\n",
    "            -   각 tree 별 사용된 feature의 퍼센테이지이다.\n",
    "            -   보통 0.5 ~ 1 사용된다.\n",
    "            -   값이 낮을수록 과적합이 방지된다.\n",
    "        -   lambda [기본값 = 1, 별칭 : reg_lambda]\n",
    "            -   가중치에 대한 L2 Regularization 적용 값\n",
    "            -   피처 개수가 많을 때 적용을 검토\n",
    "            -   이 값이 클수록 과적합 감소 효과\n",
    "        -   alpha [기본값 = 0, 별칭 : reg_alpha]\n",
    "            -   가중치에 대한 L1 Regularization 적용 값\n",
    "            -   피처 개수가 많을 때 적용을 검토\n",
    "            -   이 값이 클수록 과적합 감소 효과\n",
    "-   **학습 과정 파라미터**\n",
    "    \n",
    "    -   **objective [ 기본값 : reg = squarederror ]**\n",
    "        -   reg : squarederror\n",
    "            -   제곱 손실이 있는 회귀\n",
    "        -   binary : logistic (binary-logistic classification)\n",
    "            -   이항 분류 문제 로지스틱 회귀 모형으로 반환값이 클래스가 아니라 예측 확률\n",
    "        -   multi : softmax\n",
    "            -   다항 분류 문제의 경우 소프트맥스(Softmax)를 사용해서 분류하는데 반횐되는 값이 예측확률이 아니라 클래스임. 또한 num_class도 지정해야함.\n",
    "        -   multi : softprob\n",
    "            -   각 클래스 범주에 속하는 예측확률을 반환함.\n",
    "        -   count : poisson (count data poison regression) 등 다양하다.\n",
    "    -   eval_metric\n",
    "        -   모델의 평가 함수를 조정하는 함수다.\n",
    "        -   설정한 objective 별로 기본설정값이 지정되어 있다.\n",
    "        -   rmse: root mean square error\n",
    "        -   mae: mean absolute error\n",
    "        -   logloss: negative log-likelihood\n",
    "        -   error: Binary classification error rate (0.5 threshold)\n",
    "        -   merror: Multiclass classification error rate\n",
    "        -   mlogloss: Multiclass logloss\n",
    "        -   auc: Area under the curve\n",
    "        -   map (mean average precision)등, 해당 데이터의 특성에 맞게 평가 함수를 조정한다.\n",
    "    -   seed [ 기본값 : 0 ]\n",
    "        -   재현가능하도록 난수를 고정시킴.\n",
    "-   **민감하게 조정해야하는 것**\n",
    "    \n",
    "    -   booster 모양\n",
    "    -   eval_metric(평가함수) / objective(목적함수)\n",
    "    -   eta\n",
    "    -   L1 form (L1 레귤러라이제이션 폼이 L2보다 아웃라이어에 민감하다.)\n",
    "    -   L2 form\n",
    "-   **과적합 방지를 위해 조정해야하는 것**\n",
    "    \n",
    "    -   learning rate 낮추기 → n_estimators은 높여야함\n",
    "    -   max_depth 낮추기\n",
    "    -   min_child_weight 높이기\n",
    "    -   gamma 높이기\n",
    "    -   subsample, colsample_bytree 낮추기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a51895",
   "metadata": {},
   "source": [
    "#### Sample code 1. XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd1e35c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-02T02:51:00.104836Z",
     "start_time": "2023-02-02T02:51:00.095528Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "feature_name_df = pd.read_csv(\"./datasets/human_activity/features.txt\", sep=\"\\s+\",header=None,\n",
    "           names=[\"column_index\", 'column_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70b0e391",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-02T02:51:04.184674Z",
     "start_time": "2023-02-02T02:51:00.565708Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column_index    42\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "feature_dup_df = feature_name_df.groupby(\"column_name\").count()\n",
    "print(feature_dup_df[feature_dup_df[\"column_index\"]>1].count())\n",
    "feature_dup_df[feature_dup_df[\"column_index\"]>1].head()\n",
    "\n",
    "\n",
    "def get_new_feature_name_df(old_feature_name_df):\n",
    "    #column_name으로 중복된 컬럼명에 대해서는 중복 차수 부여, col1, col1과 같이 2개의 중복 컬럼이 있을 경우 1, 2 \n",
    "    feature_dup_df = pd.DataFrame(data=old_feature_name_df.groupby('column_name').cumcount(), columns=['dup_cnt'])\n",
    "    # feature_dup_df의 index인 column_name을 reset_index()를 이용하여 컬럼으로 변환. \n",
    "    feature_dup_df = feature_dup_df.reset_index()\n",
    "    # 인자로 받은 features_txt의 컬럼명 DataFrame과 feature_dup_df를 조인. \n",
    "    new_feature_name_df = pd.merge(old_feature_name_df.reset_index(), feature_dup_df, how='outer')\n",
    "    # 새로운 컬럼명은 앞에 중복 차수를 접미어로 결합. \n",
    "    new_feature_name_df['column_name'] = new_feature_name_df[['column_name', 'dup_cnt']].apply(lambda x : x[0]+'_'+str(x[1]) \n",
    "                                                                                           if x[1] >0 else x[0] ,  axis=1)\n",
    "    new_feature_name_df = new_feature_name_df.drop(['index'], axis=1)\n",
    "    return new_feature_name_df\n",
    "\n",
    "def get_human_dataset( ):\n",
    "    \n",
    "    # 각 데이터 파일들은 공백으로 분리되어 있으므로 read_csv에서 공백 문자를 sep으로 할당.\n",
    "    feature_name_df = pd.read_csv('./datasets/human_activity/features.txt',sep='\\s+',\n",
    "                        header=None,names=['column_index','column_name'])\n",
    "    \n",
    "    # 중복된 feature명을 새롭게 수정하는 get_new_feature_name_df()를 이용하여 새로운 feature명 DataFrame생성. \n",
    "    new_feature_name_df = get_new_feature_name_df(feature_name_df)\n",
    "    \n",
    "    # DataFrame에 피처명을 컬럼으로 부여하기 위해 리스트 객체로 다시 변환\n",
    "    feature_name = new_feature_name_df.iloc[:, 1].values.tolist()\n",
    "    \n",
    "    # 학습 피처 데이터 셋과 테스트 피처 데이터을 DataFrame으로 로딩. 컬럼명은 feature_name 적용\n",
    "    X_train = pd.read_csv('./datasets/human_activity/train/X_train.txt',sep='\\s+', names=feature_name )\n",
    "    X_test = pd.read_csv('./datasets/human_activity/test/X_test.txt',sep='\\s+', names=feature_name)\n",
    "    \n",
    "    # 학습 레이블과 테스트 레이블 데이터을 DataFrame으로 로딩하고 컬럼명은 action으로 부여\n",
    "    y_train = pd.read_csv('./datasets/human_activity/train/y_train.txt',sep='\\s+',header=None,names=['action'])\n",
    "    y_test = pd.read_csv('./datasets/human_activity/test/y_test.txt',sep='\\s+',header=None,names=['action'])\n",
    "    \n",
    "    # 로드된 학습/테스트용 DataFrame을 모두 반환 \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_human_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "011bc076",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-02T02:59:16.616229Z",
     "start_time": "2023-02-02T02:58:45.724526Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juno\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.027146250424160162"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "Y_train_1 = encoder.fit_transform(y_train)\n",
    "\n",
    "xgb_clf = xgb.XGBClassifier()\n",
    "xgb_clf.fit(X_train,Y_train_1)\n",
    "xgb_pred = xgb_clf.predict(X_test)\n",
    "xgb_accuracy = accuracy_score(y_test,xgb_pred)\n",
    "xgb_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd41d8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
